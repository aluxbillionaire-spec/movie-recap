"""
Assembly Worker

Handle video editing, assembly, and final output generation.
"""

import os
import tempfile
import subprocess
import json
from typing import Dict, Any, List, Optional
from celery import current_task
import ffmpeg
from datetime import timedelta

from app.workers.celery_app import celery_app
from app.core.config import settings


@celery_app.task(bind=True)
def assemble_video(
    self, 
    job_id: str, 
    alignments: List[Dict[str, Any]], 
    video_path: str,
    output_settings: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Assemble final video from aligned scenes.
    
    Args:
        job_id: Processing job ID
        alignments: Scene alignments with timestamps
        video_path: Path to source video
        output_settings: Custom output settings
        
    Returns:
        Assembly results with output path
    """
    
    try:
        current_task.update_state(
            state="PROGRESS",
            meta={"percent": 10, "stage": "preparing_segments", "details": {}}
        )
        
        # Prepare output settings
        settings_config = prepare_output_settings(output_settings)
        
        # Filter and prepare segments
        segments = prepare_video_segments(alignments, settings_config)
        
        current_task.update_state(
            state="PROGRESS",
            meta={"percent": 30, "stage": "extracting_clips", "details": {"segments_count": len(segments)}}
        )
        
        # Extract video clips for each segment
        clip_paths = extract_video_clips(video_path, segments, job_id)
        
        current_task.update_state(
            state="PROGRESS",
            meta={"percent": 60, "stage": "applying_effects", "details": {}}
        )
        
        # Apply video effects and transformations
        processed_clips = apply_video_effects(clip_paths, segments, settings_config)
        
        current_task.update_state(
            state="PROGRESS",
            meta={"percent": 80, "stage": "concatenating_video", "details": {}}
        )
        
        # Concatenate clips into final video
        output_path = concatenate_clips(processed_clips, job_id, settings_config)
        
        current_task.update_state(
            state="PROGRESS",
            meta={"percent": 95, "stage": "adding_intro_outro", "details": {}}
        )
        
        # Add intro/outro and final processing
        final_output = add_intro_outro(output_path, job_id, settings_config)
        
        current_task.update_state(
            state="PROGRESS",
            meta={"percent": 100, "stage": "completed", "details": {}}
        )
        
        # Cleanup temporary files
        cleanup_temp_files([output_path] + processed_clips + clip_paths)
        
        return {
            "status": "success",
            "output_path": final_output,
            "processing_info": {
                "segments_processed": len(segments),
                "total_duration": get_video_duration(final_output),
                "output_size_bytes": os.path.getsize(final_output),
                "output_settings": settings_config
            }
        }
        
    except Exception as e:
        current_task.update_state(
            state="FAILURE",
            meta={"error": str(e), "stage": "assembly"}
        )
        raise


def prepare_output_settings(custom_settings: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Prepare output settings with defaults."""
    
    default_settings = {
        "resolution": "1920x1080",  # Default to 1080p
        "fps": 30,
        "video_codec": "libx264",
        "audio_codec": "aac",
        "video_bitrate": "5000k",
        "audio_bitrate": "128k",
        "preset": "medium",
        "crf": 23,
        "max_duration": settings.MAX_OUTPUT_DURATION,
        "include_intro": True,
        "include_outro": True,
        "fade_duration": 1.0,
        "transition_type": "fade",
        "watermark_enabled": True,
        "watermark_text": "Generated by Movie Recap Pipeline"
    }
    
    if custom_settings:
        default_settings.update(custom_settings)
    
    return default_settings


def prepare_video_segments(alignments: List[Dict[str, Any]], settings_config: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Prepare video segments from alignments."""
    
    segments = []
    total_duration = 0
    max_duration = settings_config["max_duration"]
    
    # Sort alignments by scene number
    sorted_alignments = sorted(alignments, key=lambda x: x["scene_number"])
    
    for alignment in sorted_alignments:
        # Skip scenes flagged for manual review (unless approved)
        if alignment.get("manual_review_required", False) and not alignment.get("user_approved", False):
            continue
        
        # Skip low confidence scenes
        if alignment["confidence"] < settings.ALIGNMENT_CONFIDENCE_THRESHOLD:
            continue
        
        start_time = alignment["video_start_time"]
        end_time = alignment["video_end_time"]
        duration = end_time - start_time
        
        # Check if adding this segment would exceed max duration
        if total_duration + duration > max_duration:
            # Calculate remaining time
            remaining_time = max_duration - total_duration
            
            if remaining_time > 10:  # Only include if at least 10 seconds remaining
                # Trim segment to fit
                end_time = start_time + remaining_time
                duration = remaining_time
            else:
                break  # Stop adding segments
        
        segment = {
            "scene_number": alignment["scene_number"],
            "start_time": start_time,
            "end_time": end_time,
            "duration": duration,
            "confidence": alignment["confidence"],
            "transformations": alignment.get("transformations", {}),
            "scene_text": alignment.get("scene_text", "")
        }
        
        segments.append(segment)
        total_duration += duration
        
        # Stop if max duration reached
        if total_duration >= max_duration:
            break
    
    return segments


def extract_video_clips(video_path: str, segments: List[Dict[str, Any]], job_id: str) -> List[str]:
    """Extract video clips for each segment."""
    
    clip_paths = []
    
    for i, segment in enumerate(segments):
        clip_filename = f"clip_{job_id}_{i:03d}.mp4"
        clip_path = os.path.join(tempfile.gettempdir(), clip_filename)
        
        try:
            # Extract clip using ffmpeg
            (
                ffmpeg
                .input(video_path, ss=segment["start_time"], t=segment["duration"])
                .output(
                    clip_path,
                    vcodec="libx264",
                    acodec="aac",
                    preset="fast"
                )
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True)
            )
            
            clip_paths.append(clip_path)
            
        except ffmpeg.Error as e:
            print(f"Error extracting clip {i}: {e}")
            # Create a black video as fallback
            create_fallback_clip(clip_path, segment["duration"])
            clip_paths.append(clip_path)
    
    return clip_paths


def apply_video_effects(clip_paths: List[str], segments: List[Dict[str, Any]], settings_config: Dict[str, Any]) -> List[str]:
    """Apply video effects and transformations to clips."""
    
    processed_clips = []
    
    for i, (clip_path, segment) in enumerate(zip(clip_paths, segments)):
        processed_filename = f"processed_{os.path.basename(clip_path)}"
        processed_path = os.path.join(tempfile.gettempdir(), processed_filename)
        
        try:
            # Build ffmpeg filter chain
            input_stream = ffmpeg.input(clip_path)
            video_stream = input_stream['v']
            audio_stream = input_stream['a']
            
            # Apply transformations
            transformations = segment.get("transformations", {})
            
            # Horizontal flip (allowed transformation)
            if transformations.get("horizontal_flip", False):
                video_stream = video_stream.hflip()
            
            # Vertical flip (allowed transformation)
            if transformations.get("vertical_flip", False):
                video_stream = video_stream.vflip()
            
            # Rotation
            rotation = transformations.get("rotation", 0)
            if rotation != 0:
                if rotation == 90:
                    video_stream = video_stream.transpose(1)
                elif rotation == 180:
                    video_stream = video_stream.transpose(2).transpose(2)
                elif rotation == 270:
                    video_stream = video_stream.transpose(2)
            
            # Color adjustments
            if "color_adjustments" in transformations:
                color_adj = transformations["color_adjustments"]
                
                # Brightness, contrast, saturation
                if any(k in color_adj for k in ["brightness", "contrast", "saturation"]):
                    video_stream = video_stream.filter(
                        'eq',
                        brightness=color_adj.get("brightness", 0),
                        contrast=color_adj.get("contrast", 1),
                        saturation=color_adj.get("saturation", 1)
                    )
            
            # Scale to target resolution
            target_resolution = settings_config["resolution"].split("x")
            target_width, target_height = int(target_resolution[0]), int(target_resolution[1])
            
            video_stream = video_stream.filter('scale', target_width, target_height)
            
            # Add fade in/out effects
            fade_duration = settings_config.get("fade_duration", 1.0)
            video_duration = segment["duration"]
            
            if fade_duration > 0 and video_duration > fade_duration * 2:
                # Fade in
                video_stream = video_stream.filter('fade', type='in', duration=fade_duration)
                # Fade out
                video_stream = video_stream.filter('fade', type='out', start_time=video_duration-fade_duration, duration=fade_duration)
            
            # Output processed clip
            (
                ffmpeg
                .output(
                    video_stream, audio_stream, processed_path,
                    vcodec=settings_config["video_codec"],
                    acodec=settings_config["audio_codec"],
                    preset=settings_config["preset"],
                    crf=settings_config["crf"]
                )
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True)
            )
            
            processed_clips.append(processed_path)
            
        except ffmpeg.Error as e:
            print(f"Error processing clip {i}: {e}")
            # Use original clip as fallback
            processed_clips.append(clip_path)
    
    return processed_clips


def concatenate_clips(clip_paths: List[str], job_id: str, settings_config: Dict[str, Any]) -> str:
    """Concatenate video clips into final video."""
    
    if not clip_paths:
        raise Exception("No clips to concatenate")
    
    output_filename = f"assembled_{job_id}.mp4"
    output_path = os.path.join(tempfile.gettempdir(), output_filename)
    
    try:
        if len(clip_paths) == 1:
            # Single clip - just copy
            import shutil
            shutil.copy2(clip_paths[0], output_path)
        else:
            # Multiple clips - concatenate
            
            # Create file list for concat demuxer
            filelist_path = os.path.join(tempfile.gettempdir(), f"filelist_{job_id}.txt")
            with open(filelist_path, 'w') as f:
                for clip_path in clip_paths:
                    f.write(f"file '{clip_path}'\n")
            
            # Concatenate using concat demuxer (fastest method)
            (
                ffmpeg
                .input(filelist_path, format='concat', safe=0)
                .output(
                    output_path,
                    c='copy'  # Copy streams without re-encoding
                )
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True)
            )
            
            # Clean up file list
            os.remove(filelist_path)
        
        return output_path
        
    except ffmpeg.Error as e:
        print(f"Error concatenating clips: {e}")
        
        # Fallback: use filter_complex method
        return concatenate_clips_fallback(clip_paths, job_id, settings_config)


def concatenate_clips_fallback(clip_paths: List[str], job_id: str, settings_config: Dict[str, Any]) -> str:
    """Fallback concatenation method using filter_complex."""
    
    output_filename = f"assembled_fallback_{job_id}.mp4"
    output_path = os.path.join(tempfile.gettempdir(), output_filename)
    
    # Build inputs
    inputs = [ffmpeg.input(clip) for clip in clip_paths]
    
    # Build concat filter
    video_streams = [input_['v'] for input_ in inputs]
    audio_streams = [input_['a'] for input_ in inputs]
    
    concatenated_video = ffmpeg.concat(*video_streams, v=1, a=0)
    concatenated_audio = ffmpeg.concat(*audio_streams, v=0, a=1)
    
    # Output
    (
        ffmpeg
        .output(
            concatenated_video, concatenated_audio, output_path,
            vcodec=settings_config["video_codec"],
            acodec=settings_config["audio_codec"],
            preset=settings_config["preset"],
            crf=settings_config["crf"]
        )
        .overwrite_output()
        .run(capture_stdout=True, capture_stderr=True)
    )
    
    return output_path


def add_intro_outro(input_path: str, job_id: str, settings_config: Dict[str, Any]) -> str:
    """Add intro and outro to the video."""
    
    final_filename = f"final_{job_id}.mp4"
    final_path = os.path.join(tempfile.gettempdir(), final_filename)
    
    include_intro = settings_config.get("include_intro", True)
    include_outro = settings_config.get("include_outro", True)
    watermark_enabled = settings_config.get("watermark_enabled", True)
    
    try:
        input_stream = ffmpeg.input(input_path)
        video_stream = input_stream['v']
        audio_stream = input_stream['a']
        
        # Add watermark if enabled
        if watermark_enabled:
            watermark_text = settings_config.get("watermark_text", "Generated Content")
            video_stream = video_stream.filter(
                'drawtext',
                text=watermark_text,
                fontsize=24,
                fontcolor='white@0.7',
                x='w-tw-10',
                y='h-th-10',
                box=1,
                boxcolor='black@0.5',
                boxborderw=5
            )
        
        # Create intro/outro if needed
        clips_to_concat = []
        
        if include_intro:
            intro_path = create_intro_clip(job_id, settings_config)
            if intro_path:
                clips_to_concat.append(intro_path)
        
        clips_to_concat.append(input_path)
        
        if include_outro:
            outro_path = create_outro_clip(job_id, settings_config)
            if outro_path:
                clips_to_concat.append(outro_path)
        
        if len(clips_to_concat) > 1:
            # Concatenate with intro/outro
            final_path = concatenate_clips(clips_to_concat, f"final_{job_id}", settings_config)
        else:
            # Just apply watermark
            (
                ffmpeg
                .output(
                    video_stream, audio_stream, final_path,
                    vcodec=settings_config["video_codec"],
                    acodec=settings_config["audio_codec"],
                    preset=settings_config["preset"],
                    crf=settings_config["crf"],
                    movflags='faststart'  # Enable fast start for web playback
                )
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True)
            )
        
        return final_path
        
    except ffmpeg.Error as e:
        print(f"Error adding intro/outro: {e}")
        # Return original video as fallback
        return input_path


def create_intro_clip(job_id: str, settings_config: Dict[str, Any]) -> Optional[str]:
    """Create intro clip."""
    
    intro_duration = 3  # 3 seconds intro
    intro_filename = f"intro_{job_id}.mp4"
    intro_path = os.path.join(tempfile.gettempdir(), intro_filename)
    
    try:
        target_resolution = settings_config["resolution"].split("x")
        width, height = int(target_resolution[0]), int(target_resolution[1])
        
        # Create intro with text
        (
            ffmpeg
            .input('color=black:size={}x{}:duration={}'.format(width, height, intro_duration), f='lavfi')
            .filter(
                'drawtext',
                text='Movie Recap',
                fontsize=48,
                fontcolor='white',
                x='(w-tw)/2',
                y='(h-th)/2',
                enable='between(t,0.5,2.5)'
            )
            .output(
                intro_path,
                vcodec=settings_config["video_codec"],
                preset='fast',
                crf=23,
                pix_fmt='yuv420p'
            )
            .overwrite_output()
            .run(capture_stdout=True, capture_stderr=True)
        )
        
        return intro_path
        
    except Exception as e:
        print(f"Error creating intro: {e}")
        return None


def create_outro_clip(job_id: str, settings_config: Dict[str, Any]) -> Optional[str]:
    """Create outro clip."""
    
    outro_duration = 2  # 2 seconds outro
    outro_filename = f"outro_{job_id}.mp4"
    outro_path = os.path.join(tempfile.gettempdir(), outro_filename)
    
    try:
        target_resolution = settings_config["resolution"].split("x")
        width, height = int(target_resolution[0]), int(target_resolution[1])
        
        # Create outro with text
        (
            ffmpeg
            .input('color=black:size={}x{}:duration={}'.format(width, height, outro_duration), f='lavfi')
            .filter(
                'drawtext',
                text='Thank you for watching',
                fontsize=36,
                fontcolor='white',
                x='(w-tw)/2',
                y='(h-th)/2'
            )
            .output(
                outro_path,
                vcodec=settings_config["video_codec"],
                preset='fast',
                crf=23,
                pix_fmt='yuv420p'
            )
            .overwrite_output()
            .run(capture_stdout=True, capture_stderr=True)
        )
        
        return outro_path
        
    except Exception as e:
        print(f"Error creating outro: {e}")
        return None


def create_fallback_clip(output_path: str, duration: float):
    """Create a black video clip as fallback."""
    
    try:
        (
            ffmpeg
            .input('color=black:size=1920x1080:duration={}'.format(duration), f='lavfi')
            .filter(
                'drawtext',
                text='Content Unavailable',
                fontsize=48,
                fontcolor='white',
                x='(w-tw)/2',
                y='(h-th)/2'
            )
            .output(output_path, vcodec='libx264', preset='fast', crf=23)
            .overwrite_output()
            .run(capture_stdout=True, capture_stderr=True)
        )
    except Exception as e:
        print(f"Error creating fallback clip: {e}")


def get_video_duration(video_path: str) -> float:
    """Get video duration in seconds."""
    
    try:
        probe = ffmpeg.probe(video_path)
        duration = float(probe['format']['duration'])
        return duration
    except Exception:
        return 0.0


def cleanup_temp_files(file_paths: List[str]):
    """Clean up temporary files."""
    
    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
        except Exception as e:
            print(f"Error cleaning up {file_path}: {e}")


@celery_app.task(bind=True)
def generate_thumbnails(self, job_id: str, video_path: str, count: int = 5) -> Dict[str, Any]:
    """Generate thumbnails from the final video."""
    
    try:
        duration = get_video_duration(video_path)
        if duration <= 0:
            raise Exception("Invalid video duration")
        
        thumbnails = []
        
        # Generate thumbnails at regular intervals
        for i in range(count):
            timestamp = (duration / (count + 1)) * (i + 1)
            thumbnail_filename = f"thumb_{job_id}_{i}.jpg"
            thumbnail_path = os.path.join(tempfile.gettempdir(), thumbnail_filename)
            
            try:
                (
                    ffmpeg
                    .input(video_path, ss=timestamp)
                    .filter('scale', 320, 180)
                    .output(thumbnail_path, vframes=1, format='image2')
                    .overwrite_output()
                    .run(capture_stdout=True, capture_stderr=True)
                )
                
                thumbnails.append({
                    "index": i,
                    "timestamp": timestamp,
                    "path": thumbnail_path
                })
                
            except ffmpeg.Error as e:
                print(f"Error generating thumbnail {i}: {e}")
        
        return {
            "status": "success",
            "thumbnails": thumbnails,
            "count": len(thumbnails)
        }
        
    except Exception as e:
        current_task.update_state(
            state="FAILURE",
            meta={"error": str(e), "stage": "thumbnail_generation"}
        )
        raise